---
title: "Luminex Xponent: Multiple Plates (QC, Aggregation, Median MFI standardization"
author: "Sahal Thahir & Jeff Bailey"
date: "2024-06-11"
params:
  input_file_folder: "data/raw/luminex"  # Path to the input folder containing CSV files
  min_beadcount: 50  # Minimum bead count for well bead QC
  min_Rsquared: 0.90 # Minimum R-squared for passing standard curve QC
  file_path: "data/qc"  # Output filepath for plate-level plots and PDFs
  background: "BSA" # Name the analyte column for background subtraction
  standards: ["AMA1", "CelTos", "HRPII"] # List of standard analytes, use ["Analyte1", "Analyte2", etc.]
output:
  pdf_document:
    toc: true  # Include table of contents
---

## Aim

This code aims to perform plate-level quality control analysis for Luminex
studies through bead counts, Background MFI, and Standard curve
analysis.

### Instructions

1. **Modify YAML Parameters:**
   - Open this document in RStudio.
   - Edit the YAML parameters at the top of the document:
     - `input_file_folder`: Path to your input folder containing CSV files.
     - `min_beadcount`: Set the minimum bead count threshold.
     - `min_Rsquared`: Set the minimum R-squared value for standard curve QC.
     - `file_path`: Specify the output directory for plots and PDFs.

2. **Run the Analysis:**
   - After modifying the YAML parameters, click the *knit* button at the top of the page to generate the report.

### Code Explanation
#### Dependencies
- `r R.version.string`
  - `tidyverse` (v. `r packageVersion("tidyverse")`)
  - `here` (v. `r packageVersion("here")`)
  - `gridExtra` (v. `r packageVersion("gridExtra")`)
  - `stringr` (v. `r packageVersion("stringr")`)

This code chunk will ensure these packages are installed and loaded.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set()

library(tidyverse)
library(here)
library(gridExtra)
library(stringr)

# Ensure all necessary packages are installed and loaded
required_packages <- c("tidyverse", "here", "gridExtra", "stringr")
lapply(required_packages, function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
})
```


## Project- level Quality Control
### Blurb for Explanation

This is designed to perform plate-level quality control analysis for Luminex assays. The process involves the following steps:

1. **Setup and Initialization**: Load necessary libraries and ensure all required packages are installed.

2. **Reading Input Files**: Read the directory path from the parameters and list all CSV files in the specified folder.

3. **Processing Each File**: For each CSV file:
    - **Data Extraction**: Extract median MFI and bead count data.
    - **Data Alignment**: Ensure the data frames are properly aligned and contain no missing values.
    - **Bead Count Quality Control**: Identify and mark wells with low bead counts, generating a list of these wells and creating visual plots.
    - **Background MFI Subtraction**: Subtract background MFI values from the median MFI data.
    - **Standard Curve Analysis**: Evaluate standard curves for specified analytes, calculate R-squared values, and create plots for visualization.
    - **Final Data Cleaning**: Modify the median MFI data based on the QC results and export cleaned data.

4. **Creating Summary Files**:
    - **Standard QC Results**: Compile and save the results of the standard curve QC for each plate.
    - **Bead QC Data**: Combine and save the bead QC data from all plates into a single CSV file.

This document helps ensure that the data from Luminex assays meet the necessary quality standards, making it easier to identify and address any issues with bead counts or standard curve linearity. The final cleaned data and QC results are saved for further analysis and record-keeping.


```{r QC of raw files, echo=FALSE, message=FALSE, warning=FALSE}
  # Read directory path from parameters
  input_file_folder <- params$input_file_folder
  
  # List all CSV files in the directory
  file_paths <- list.files(input_file_folder, pattern = "\\.csv$", full.names = TRUE)
  
  # Initialize a list to store the standard curve QC results
  standard_qc_results <- list()
  
  # Function to process each file and collect QC results
  process_file <- function(file_path) {
    min_beadcount <- params$min_beadcount
    min_Rsquared <- params$min_Rsquared
    file_path_output <- params$file_path
    background_col <- params$background
    standards <- params$standards
  
    # Raw data import
    lines <- readLines(file_path)
  
  # Median MFI extraction
  median_row_index <- grep("Median", lines)
  net_mfi_row_index <- grep("Net MFI", lines)
  
  # Check if the required keywords are found
  if (length(median_row_index) == 0 | length(net_mfi_row_index) == 0) {
    cat("Skipping file due to missing 'Median' or 'Net MFI' keywords:", file_path, "\n")
    return(NULL)
  }
  
  net_mfi_row_index <- net_mfi_row_index - 2
  data_lines <- lines[(median_row_index + 1):net_mfi_row_index]
  medianMFI_df <- read.csv(text = paste(data_lines, collapse = "\n"), na.strings = "")
  location_index <- grep("Location", colnames(medianMFI_df))
  total_events_index <- grep("Total.Events", colnames(medianMFI_df))
  medianMFI_df <- medianMFI_df[, c(location_index, (location_index + 1):(total_events_index - 1))]

  # Bead count extraction
  start_row <- grep("DataType", lines)
  start_row <- start_row[grepl("Count", lines[start_row])]
  start_row <- start_row[!grepl("Per Bead", lines[start_row])]
  start_row <- max(start_row) + 1
  end_row <- grep("Avg Net MFI", lines) - 2
  if (length(start_row) > 0 & length(end_row) > 0) {
    beadcount_df <- read.csv(text = paste(lines[start_row:end_row], collapse = "\n"))
    location_index <- grep("Location", colnames(beadcount_df))
    total_events_index <- grep("Total.Events", colnames(beadcount_df))
    beadcount_df <- beadcount_df[, c(location_index, (location_index + 1):(total_events_index - 1))]
  } else {
    beadcount_df <- NULL
  }

  # Ensure data alignment
  if (any(is.na(medianMFI_df$Location)) | any(is.na(beadcount_df$Location))) {
    stop("Missing values found in the 'Location' column.")
  }
  if (any(is.na(medianMFI_df$Sample)) | any(is.na(beadcount_df$Sample))) {
    stop("Missing values found in the 'Sample' column.")
  }
  if (!identical(colnames(medianMFI_df), colnames(beadcount_df))) {
    stop("The column names do not match between the median MFI and bead count data frames.")
  }
  print("Column names are consistent between the median MFI and bead count data frames.")

  # Identify low bead count wells
  for (col in names(beadcount_df)[sapply(beadcount_df, is.numeric)]) {
    beadcount_df[[col]][beadcount_df[[col]] < min_beadcount] <- "Failed QC (bead)"
  }
  beadqc_low_df <- beadcount_df %>%
    pivot_longer(cols = -c(Location, Sample), names_to = "Antigen", values_to = "Value") %>%
    filter(Value == "Failed QC (bead)") %>%
    select(Location, Sample, Antigen) %>%
    mutate(Plate = gsub("\\.csv$", "", basename(file_path)))
  output_file_list <- file.path(file_path_output, paste0(tools::file_path_sans_ext(basename(file_path)), "_beadqc_low_df.csv"))
  write.csv(beadqc_low_df, file = output_file_list, row.names = FALSE)
  cat("The bead QC list has been exported to", output_file_list, "\n")

  # Well schematic and heatmap generation
  beadqc_low_df$row_col <- str_extract(beadqc_low_df$Location, "(?<=,).*(?=\\))")
  beadqc_low_df$row <- str_extract(beadqc_low_df$Location, "^[A-Z]")
  beadqc_low_df$col <- str_extract(beadqc_low_df$Location, "[0-9]+$")

  # Create plate layout with row_col column
  plate_layout <- expand.grid(
    row = LETTERS[1:8],
    col = as.character(1:12)
  )
  plate_layout$row_col <- paste0(plate_layout$row, plate_layout$col)

  # Merge with low well locations to mark low wells
  plate_layout$is_low <- plate_layout$row_col %in% beadqc_low_df$row_col

  # Generate the plot
  title <- paste("96-well schematic of Plate: ", gsub(".csv", "", basename(file_path)))
  plate_plot <- ggplot(plate_layout, aes(x = col, y = row, fill = is_low)) +
    geom_tile(color = "black") +
    scale_fill_manual(values = c("deepskyblue3", "darkred"), labels = c("Passed", "Low bead count")) +
    labs(x = "Column", y = "Row", title = title, fill = "Bead Count") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust = 1),
          axis.text.y = element_text(angle = 0, vjust = 0.5, hjust = 1)) +
    guides(fill = guide_legend(title = "Bead count QC"))

  # Modify the y-axis to have the top row as "A" and the bottom row as "H"
  plate_plot <- plate_plot + scale_y_discrete(limits = rev(levels(factor(plate_layout$row))))

  # Display the plot
  print(plate_plot)

  # Background MFI subtraction
  if (!background_col %in% names(medianMFI_df)) {
    stop(paste("Background column", background_col, "not found in medianMFI_df"))
  }
  background_values <- medianMFI_df[[background_col]]
  for (col in names(medianMFI_df)[sapply(medianMFI_df, is.numeric) & names(medianMFI_df) != background_col]) {
    medianMFI_df[[col]] <- medianMFI_df[[col]] - background_values
  }
  cat("Background MFI subtraction completed.\n")

  # Standard curves
  analytes <- params$standards
  valid_analytes <- analytes[analytes %in% names(medianMFI_df)]
  if (length(valid_analytes) != length(analytes)) {
    warning("The following analytes were not found in the data frame and will be ignored: ", 
            paste(setdiff(analytes, valid_analytes), collapse = ", "))
  }

  plate_qc <- data.frame(Analyte = character(), R_squared = numeric())
  calculate_correlation <- function(df) {
    lm_model <- lm(Log10_MFI ~ Dilution_Factor, data = df)
    correlation <- cor(df$Log10_MFI, df$Dilution_Factor)
    r_squared <- summary(lm_model)$r.squared
    return(list(correlation = correlation, r_squared = r_squared))
  }

  standards_df <- medianMFI_df %>%
    filter(str_detect(Sample, "Standard")) %>%
    mutate(Dilution_Factor = -as.numeric(str_extract(Sample, "\\d+")))

  melted_df <- standards_df %>%
    select(-Sample) %>%
    pivot_longer(cols = all_of(valid_analytes), 
                 names_to = "Analyte", 
                 values_to = "MFI") %>%
    mutate(Log10_MFI = log10(MFI + 1))

  plots_list <- lapply(unique(melted_df$Analyte), function(analyte) {
    analyte_df <- filter(melted_df, Analyte == analyte & !is.na(Log10_MFI) & !is.infinite(Log10_MFI))
    if (nrow(analyte_df) == 0) {
      message(paste("No valid data for analyte:", analyte))
      return(NULL)
    }
    plot <- ggplot(analyte_df, aes(x = Dilution_Factor, y = Log10_MFI)) +
      geom_point() +
      geom_smooth(method = "lm", se = FALSE, color = "blue") +
      labs(title = paste("Standard curve for", analyte),
           x = "Dilution Factor",
           y = "Log10(MFI)") +
      theme_minimal()
    correlation_r_squared <- calculate_correlation(analyte_df)
    plot <- plot + 
      annotate("text", x = Inf, y = -Inf, 
               label = paste("R^2 =", round(correlation_r_squared$r_squared, 2)), 
               hjust = 1, vjust = 0)
    plate_qc <<- bind_rows(plate_qc, data.frame(Analyte = analyte, R_squared = correlation_r_squared$r_squared))
    return(plot)
  })

  combined_plots <- do.call(gridExtra::grid.arrange, c(plots_list, ncol = 2))
  print(combined_plots)

  # R-squared calculation
  min_Rsquared <- as.numeric(params$min_Rsquared)
  plate_qc <- plate_qc %>%
    distinct() %>%
    mutate(min_Rsq = R_squared > min_Rsquared)

  # Append the QC result for this file to the standard_qc_results list
  standard_qc_results <<- append(standard_qc_results, list(data.frame(
    Plate = basename(file_path),
    Passed_QC = any(plate_qc$min_Rsq)
  )))

  if (any(plate_qc$min_Rsq)) {
    print("This plate has passed plate-level quality control for standard curve linearity.")
    print("At least one analyte meets the criteria for the preset minimum R-squared (see min_Rsquared in YAML).")
    print("Median MFI from this plate will be included in the compiled study dataframe.")
  } else {
    print("This plate has failed plate-level QC for standard curves.")
    print("No analytes met the preset minimum R-squared (see min_Rsquared in YAML).")
    print("All MFI values from this plate will display as `Failed Plate QC`.")
  }

  # Final Clean Data
  output_dir <- "data/clean/luminex"
  output_file <- file.path(output_dir, paste0(tools::file_path_sans_ext(basename(file_path)), "_clean.csv"))

  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }

  plate_name <- tools::file_path_sans_ext(basename(file_path))
  passing_standards <- plate_qc$Analyte[plate_qc$min_Rsq]
  passing_standards_str <- paste(passing_standards, collapse = "; ")

  if (any(plate_qc$min_Rsq)) {
    clean_medianMFI_df <- medianMFI_df %>%
      mutate(across(where(is.numeric), ~ ifelse(is.na(.), "Failed QC (bead)", .)))
    cat("Plate passed QC. All NA values have been replaced with 'Failed QC (bead)'.\n")
  } else {
    clean_medianMFI_df <- medianMFI_df %>%
      mutate(across(where(is.numeric), ~ "Failed QC (standards)"))
    cat("Plate failed QC. All median MFI data set to 'Failed QC (standards)'.\n")
  }

  clean_medianMFI_df <- clean_medianMFI_df %>%
    mutate(Plate = plate_name, 
           Standard = passing_standards_str)

  write.csv(clean_medianMFI_df, file = output_file, row.names = FALSE)
  cat("The cleaned median MFI data has been exported to", output_file,". The plate name and standards which met the minimum R squared have been included in the cleaned median MFI file. \n")
}

# Process each file
lapply(file_paths, process_file)

```

```{r QC summary csv files, echo=FALSE}
# Extract project name from the filenames in the raw data folder
raw_files <- list.files("data/raw/luminex", pattern = "\\.csv$", full.names = TRUE)
first_file_name <- basename(raw_files[1])
project_name <- unlist(strsplit(first_file_name, "_"))[1]

# Combine the QC results into a single data frame
all_plates_standardsqc <- do.call(rbind, standard_qc_results)

# Write the standard QC results to a CSV file with the project name prefixed
output_standard_qc <- file.path("data/qc", paste0(project_name, "_all_plates_standardsqc.csv"))
write.csv(all_plates_standardsqc, file = output_standard_qc, row.names = FALSE)
cat("Standard QC results have been exported to", output_standard_qc, "\n")

# Compile all the "beadqc_low_df" CSVs into a single CSV file
beadqc_files <- list.files("data/qc", pattern = "_beadqc_low_df\\.csv$", full.names = TRUE)
compiled_beadqc_data <- list()

# Read and combine each bead QC file
for (beadqc_file in beadqc_files) {
  beadqc_data <- read.csv(beadqc_file)
  compiled_beadqc_data <- append(compiled_beadqc_data, list(beadqc_data))
}

# Combine the bead QC data into a single data frame
all_plates_beadqc <- do.call(rbind, compiled_beadqc_data)

# Write the compiled bead QC data to a CSV file with the project name prefixed
output_beadqc <- file.path("data/qc", paste0(project_name, "_all_plates_beadqc.csv"))
write.csv(all_plates_beadqc, file = output_beadqc, row.names = FALSE)
cat("Compiled bead QC data has been exported to", output_beadqc, "\n")


```


```{r aggregate clean data, echo=FALSE, message=FALSE, warning=FALSE}
# Function to rename analyte columns
rename_analyte_columns <- function(df, file_name) {
  # Extract the subclass from the file name
  file_parts <- unlist(strsplit(file_name, "_"))
  subclass <- file_parts[3] # Assuming the third part is the subclass
  
  # Rename the analyte columns
  analyte_cols <- colnames(df)[-(1:2)]
  new_analyte_cols <- paste(analyte_cols, subclass, sep = "_")
  colnames(df)[-(1:2)] <- new_analyte_cols
  
  return(df)
}

```

